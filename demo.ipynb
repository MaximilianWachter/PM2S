{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Demo usage</h1></center>\n",
    "\n",
    "1. Beat tracking from MIDI performance recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm2s.features.beat import RNNJointBeatProcessor\n",
    "\n",
    "# Path to the MIDI recording\n",
    "midi_recording = '/import/c4dm-05/ll307/datasets/A-MAPS_1.1/MAPS_MUS-alb_esp2_SptkBGAm.mid'\n",
    "\n",
    "# Create a beat processor\n",
    "processor = RNNJointBeatProcessor()\n",
    "\n",
    "# Process the MIDI recording to the beat predictions\n",
    "beats = processor.process(midi_recording)\n",
    "print(beats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the beat prediction and piano for the first 30 seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pretty_midi as pm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_piano_roll(midi_file, start_time, end_time):\n",
    "\n",
    "    pr = np.zeros((128, int((end_time - start_time) * 100)))\n",
    "\n",
    "    for instrument in pm.PrettyMIDI(midi_file).instruments:\n",
    "        for note in instrument.notes:\n",
    "            if note.start >= end_time or note.end <= start_time:\n",
    "                continue\n",
    "            start = int((note.start - start_time) * 100)\n",
    "            end = int((note.end - start_time) * 100)\n",
    "\n",
    "            pr[note.pitch, start:end] = 1\n",
    "    \n",
    "    return pr\n",
    "\n",
    "start_time, end_time = 0, 30\n",
    "beats_seg = beats[np.logical_and(beats >= start_time, beats <= end_time)]\n",
    "pr_seg = get_piano_roll(midi_recording, start_time, end_time)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.imshow(pr_seg, aspect='auto', origin='lower')\n",
    "for b in beats_seg:\n",
    "    plt.axvline((b - start_time) * 100, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Quantisation from MIDI performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm2s.features.quantisation import RNNJOintQuantisationProcessor\n",
    "\n",
    "# Path to the MIDI recording\n",
    "midi_recording = '/import/c4dm-05/ll307/datasets/A-MAPS_1.1/MAPS_MUS-alb_esp2_SptkBGAm.mid'\n",
    "\n",
    "# Create a beat processor\n",
    "processor = RNNJOintQuantisationProcessor(beat_model_checkpoint='/import/c4dm-05/ll307/workspace/PM2S-draft/mlruns/1/c083be0e407c4ef898896cc8fb23a0f9/checkpoints/epoch=15-val_loss=3.38-val_f1=0.00.ckpt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.4.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.4.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "513c34b582369c042e4c09b2082a0eee972fc3557bcb2c161c81e814cba2f5b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
